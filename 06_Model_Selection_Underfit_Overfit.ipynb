{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600067409618",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection : Underfitting, Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = 5 + 1.2*x -3.4*x^2 + 5.6*x^3 + ... $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "labels = y; \n",
    "poly_features = x and its poly featues\n",
    "true_w = coefficients\n",
    "features = random variable '''\n",
    "\n",
    "max_degrees = 20\n",
    "n_train, n_test = 100, 100 \n",
    "true_w = np.zeros(max_degrees)  # Allocate lots of space\n",
    "true_w[:4] = [5, 1.2, -3.4, 5.6]  # \n",
    "\n",
    "features = np.random.normal(size = (n_train + n_test, 1))\n",
    "np.random.shuffle(features)\n",
    "poly_features = np.power(features, np.arange(max_degrees).reshape(1, -1))\n",
    "labels = np.dot(poly_features, true_w)\n",
    "labels += np.random.normal(scale=0.1, size=labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from NumPy ndarrays to tensors\n",
    "true_w, features, poly_features, labels = [tf.constant(x, dtype=\n",
    "    tf.float32) for x in [true_w, features, poly_features, labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "\n",
    "def load_data(data, batch_size, is_train = False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.shuffle(buffer_size= 100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Normal Fitting (3rd Order Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch : 0, training_loss : 490.5354309082031\nepoch : 1, training_loss : 421.7524108886719\nepoch : 2, training_loss : 368.8340148925781\nepoch : 3, training_loss : 312.6621398925781\nepoch : 4, training_loss : 262.5940246582031\nepoch : 5, training_loss : 222.88475036621094\nepoch : 6, training_loss : 185.66781616210938\nepoch : 7, training_loss : 156.61898803710938\nepoch : 8, training_loss : 133.21771240234375\nepoch : 9, training_loss : 110.05538940429688\nepoch : 10, training_loss : 91.99735260009766\nepoch : 11, training_loss : 76.12255859375\nepoch : 12, training_loss : 61.9316291809082\nepoch : 13, training_loss : 50.57186508178711\nepoch : 14, training_loss : 42.35611343383789\nepoch : 15, training_loss : 34.32460021972656\nepoch : 16, training_loss : 28.032285690307617\nepoch : 17, training_loss : 23.454124450683594\nepoch : 18, training_loss : 20.195005416870117\nepoch : 19, training_loss : 17.470544815063477\nepoch : 20, training_loss : 15.255690574645996\nepoch : 21, training_loss : 13.543981552124023\nepoch : 22, training_loss : 12.096962928771973\nepoch : 23, training_loss : 11.018515586853027\nepoch : 24, training_loss : 10.21281909942627\nepoch : 25, training_loss : 9.533918380737305\nepoch : 26, training_loss : 9.00513744354248\nepoch : 27, training_loss : 8.550409317016602\nepoch : 28, training_loss : 8.136160850524902\nepoch : 29, training_loss : 7.817544460296631\nepoch : 30, training_loss : 7.513394355773926\nepoch : 31, training_loss : 7.25123405456543\nepoch : 32, training_loss : 7.0096211433410645\nepoch : 33, training_loss : 6.778630256652832\nepoch : 34, training_loss : 6.564555644989014\nepoch : 35, training_loss : 6.388774394989014\nepoch : 36, training_loss : 6.180289268493652\nepoch : 37, training_loss : 6.003347873687744\nepoch : 38, training_loss : 5.826134204864502\nepoch : 39, training_loss : 5.644701957702637\nepoch : 40, training_loss : 5.491189956665039\nepoch : 41, training_loss : 5.317388534545898\nepoch : 42, training_loss : 5.156390190124512\nepoch : 43, training_loss : 5.002895355224609\nepoch : 44, training_loss : 4.8506622314453125\nepoch : 45, training_loss : 4.715814590454102\nepoch : 46, training_loss : 4.564377307891846\nepoch : 47, training_loss : 4.425409317016602\nepoch : 48, training_loss : 4.290487289428711\nepoch : 49, training_loss : 4.162567615509033\n"
    }
   ],
   "source": [
    "num_epochs, batch_size, lr = 50, 10, 0.05\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "\n",
    "net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "data_iter = load_data((poly_features[:n_train, :4], labels[:n_train]), batch_size, is_train = True)\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        with tf.GradientTape() as tape:\n",
    "            yhat = net(X)\n",
    "            mse_loss = loss(yhat, y)\n",
    "        \n",
    "        grads = tape.gradient(mse_loss, net.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, net.trainable_variables))\n",
    "\n",
    "    epoch_loss = loss(net(poly_features[:n_train, :4]), labels[:n_train])\n",
    "    training_loss.append(epoch_loss)\n",
    "    print(f\"epoch : {epoch}, training_loss : {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x13ce7f48>]"
     },
     "metadata": {},
     "execution_count": 43
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 375.2875 248.518125 \r\nL 375.2875 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 33.2875 224.64 \r\nL 368.0875 224.64 \r\nL 368.0875 7.2 \r\nL 33.2875 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m42279b2e3b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#m42279b2e3b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(45.324432 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.62071\" xlink:href=\"#m42279b2e3b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(104.25821 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.735737\" xlink:href=\"#m42279b2e3b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(166.373237 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.850765\" xlink:href=\"#m42279b2e3b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(228.488265 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"296.965793\" xlink:href=\"#m42279b2e3b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(290.603293 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.080821\" xlink:href=\"#m42279b2e3b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(352.718321 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"me859e754f3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me859e754f3\" y=\"216.448124\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(19.925 220.247342)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me859e754f3\" y=\"175.805904\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(7.2 179.605123)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me859e754f3\" y=\"135.163684\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(7.2 138.962903)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me859e754f3\" y=\"94.521465\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 300 -->\r\n      <g transform=\"translate(7.2 98.320683)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me859e754f3\" y=\"53.879245\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 400 -->\r\n      <g transform=\"translate(7.2 57.678464)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me859e754f3\" y=\"13.237025\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 500 -->\r\n      <g transform=\"translate(7.2 17.036244)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p7c2adfb254)\" d=\"M 48.505682 17.083636 \r\nL 54.717185 45.038582 \r\nL 60.928687 66.545793 \r\nL 67.14019 89.37529 \r\nL 73.351693 109.724083 \r\nL 79.563196 125.862814 \r\nL 85.774699 140.988602 \r\nL 91.986201 152.79469 \r\nL 98.197704 162.305488 \r\nL 104.409207 171.71917 \r\nL 110.62071 179.058357 \r\nL 116.832212 185.510226 \r\nL 123.043715 191.277735 \r\nL 129.255218 195.894595 \r\nL 135.466721 199.233659 \r\nL 141.678224 202.497844 \r\nL 147.889726 205.05518 \r\nL 154.101229 206.915847 \r\nL 160.312732 208.240425 \r\nL 166.524235 209.347706 \r\nL 172.735737 210.247872 \r\nL 178.94724 210.943549 \r\nL 185.158743 211.531649 \r\nL 191.370246 211.969954 \r\nL 197.581749 212.297407 \r\nL 203.793251 212.573327 \r\nL 210.004754 212.788236 \r\nL 216.216257 212.973047 \r\nL 222.42776 213.141407 \r\nL 228.639263 213.2709 \r\nL 234.850765 213.394513 \r\nL 241.062268 213.501061 \r\nL 247.273771 213.599258 \r\nL 253.485274 213.693138 \r\nL 259.696776 213.780142 \r\nL 265.908279 213.851584 \r\nL 272.119782 213.936317 \r\nL 278.331285 214.00823 \r\nL 284.542788 214.080253 \r\nL 290.75429 214.153991 \r\nL 296.965793 214.216382 \r\nL 303.177296 214.287019 \r\nL 309.388799 214.352452 \r\nL 315.600301 214.414836 \r\nL 321.811804 214.476707 \r\nL 328.023307 214.531512 \r\nL 334.23481 214.593059 \r\nL 340.446313 214.649539 \r\nL 346.657815 214.704374 \r\nL 352.869318 214.756364 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 33.2875 224.64 \r\nL 33.2875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 368.0875 224.64 \r\nL 368.0875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 33.2875 224.64 \r\nL 368.0875 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 33.2875 7.2 \r\nL 368.0875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p7c2adfb254\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(range(num_epochs), training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=5.0580416>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "loss(net(poly_features[n_train:, :4]), labels[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Underfit Model (1st Deg Polyomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch : 0, training_loss : 546.1493530273438\nepoch : 1, training_loss : 545.220703125\nepoch : 2, training_loss : 544.6514282226562\nepoch : 3, training_loss : 544.2748413085938\nepoch : 4, training_loss : 543.8222045898438\nepoch : 5, training_loss : 543.5359497070312\nepoch : 6, training_loss : 543.0966186523438\nepoch : 7, training_loss : 542.8233032226562\nepoch : 8, training_loss : 542.708251953125\nepoch : 9, training_loss : 542.6119384765625\nepoch : 10, training_loss : 542.6213989257812\nepoch : 11, training_loss : 542.5575561523438\nepoch : 12, training_loss : 542.5348510742188\nepoch : 13, training_loss : 542.5260620117188\nepoch : 14, training_loss : 542.506103515625\nepoch : 15, training_loss : 542.4821166992188\nepoch : 16, training_loss : 542.48291015625\nepoch : 17, training_loss : 542.4754028320312\nepoch : 18, training_loss : 542.470703125\nepoch : 19, training_loss : 542.462646484375\nepoch : 20, training_loss : 542.4767456054688\nepoch : 21, training_loss : 542.4776000976562\nepoch : 22, training_loss : 542.4744262695312\nepoch : 23, training_loss : 542.4678955078125\nepoch : 24, training_loss : 542.46435546875\nepoch : 25, training_loss : 542.4707641601562\nepoch : 26, training_loss : 542.465576171875\nepoch : 27, training_loss : 542.4636840820312\nepoch : 28, training_loss : 542.4652099609375\nepoch : 29, training_loss : 542.463623046875\nepoch : 30, training_loss : 542.464599609375\nepoch : 31, training_loss : 542.4630126953125\nepoch : 32, training_loss : 542.462646484375\nepoch : 33, training_loss : 542.4666748046875\nepoch : 34, training_loss : 542.46826171875\nepoch : 35, training_loss : 542.4628295898438\nepoch : 36, training_loss : 542.4700927734375\nepoch : 37, training_loss : 542.4716796875\nepoch : 38, training_loss : 542.4671020507812\nepoch : 39, training_loss : 542.4658203125\nepoch : 40, training_loss : 542.4635009765625\nepoch : 41, training_loss : 542.4642944335938\nepoch : 42, training_loss : 542.469970703125\nepoch : 43, training_loss : 542.4629516601562\nepoch : 44, training_loss : 542.462646484375\nepoch : 45, training_loss : 542.4637451171875\nepoch : 46, training_loss : 542.4627075195312\nepoch : 47, training_loss : 542.462646484375\nepoch : 48, training_loss : 542.4639282226562\nepoch : 49, training_loss : 542.46337890625\n"
    }
   ],
   "source": [
    "\n",
    "net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "\n",
    "num_epochs, batch_size, lr = 50, 10, 0.05\n",
    "\n",
    "data_iter = load_data((poly_features[:n_train, :1], labels[:n_train]), batch_size, is_train = True)\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        with tf.GradientTape() as tape:\n",
    "            yhat = net(X)\n",
    "            mse_loss = loss(yhat, y)\n",
    "        \n",
    "        grads = tape.gradient(mse_loss, net.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, net.trainable_variables))\n",
    "\n",
    "    epoch_loss = loss(net(poly_features[:n_train, :1]), labels[:n_train])\n",
    "    training_loss.append(epoch_loss)\n",
    "    print(f\"epoch : {epoch}, training_loss : {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=472.63507>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "loss(net(poly_features[n_train:, :1]), labels[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Overfit Model (8th Deg Polyomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch : 0, training_loss : 3300252188672.0\nepoch : 1, training_loss : 320698974208.0\nepoch : 2, training_loss : 155972141056.0\nepoch : 3, training_loss : 93067010048.0\nepoch : 4, training_loss : 20524584960.0\nepoch : 5, training_loss : 439203201024.0\nepoch : 6, training_loss : 123312119808.0\nepoch : 7, training_loss : 8233865728.0\nepoch : 8, training_loss : 40184811520.0\nepoch : 9, training_loss : 26298054656.0\nepoch : 10, training_loss : 17092548608.0\nepoch : 11, training_loss : 72190672896.0\nepoch : 12, training_loss : 170609442816.0\nepoch : 13, training_loss : 16988925952.0\nepoch : 14, training_loss : 8570759168.0\nepoch : 15, training_loss : 18510536704.0\nepoch : 16, training_loss : 29668943872.0\nepoch : 17, training_loss : 4102684672.0\nepoch : 18, training_loss : 3039508224.0\nepoch : 19, training_loss : 538254278656.0\nepoch : 20, training_loss : 30825093120.0\nepoch : 21, training_loss : 758166272.0\nepoch : 22, training_loss : 54551142400.0\nepoch : 23, training_loss : 80240001024.0\nepoch : 24, training_loss : 43824967680.0\nepoch : 25, training_loss : 4985526784.0\nepoch : 26, training_loss : 3882216704.0\nepoch : 27, training_loss : 176815816704.0\nepoch : 28, training_loss : 2764811272192.0\nepoch : 29, training_loss : 436803764224.0\nepoch : 30, training_loss : 1888924073984.0\nepoch : 31, training_loss : 868668608.0\nepoch : 32, training_loss : 274041503744.0\nepoch : 33, training_loss : 27784142848.0\nepoch : 34, training_loss : 184955712.0\nepoch : 35, training_loss : 76693594112.0\nepoch : 36, training_loss : 33282342912.0\nepoch : 37, training_loss : 376370720.0\nepoch : 38, training_loss : 2228672512.0\nepoch : 39, training_loss : 73911754752.0\nepoch : 40, training_loss : 50501476352.0\nepoch : 41, training_loss : 41676398592.0\nepoch : 42, training_loss : 18464350208.0\nepoch : 43, training_loss : 17414332416.0\nepoch : 44, training_loss : 70664839168.0\nepoch : 45, training_loss : 943896723456.0\nepoch : 46, training_loss : 1179123580928.0\nepoch : 47, training_loss : 98322866176.0\nepoch : 48, training_loss : 479838011392.0\nepoch : 49, training_loss : 315095056384.0\n"
    }
   ],
   "source": [
    "\n",
    "net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "\n",
    "num_epochs, batch_size, lr = 50, 10, 0.05\n",
    "\n",
    "data_iter = load_data((poly_features[:n_train, :], labels[:n_train]), batch_size, is_train = True)\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        with tf.GradientTape() as tape:\n",
    "            yhat = net(X)\n",
    "            mse_loss = loss(yhat, y)\n",
    "        \n",
    "        grads = tape.gradient(mse_loss, net.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, net.trainable_variables))\n",
    "\n",
    "    epoch_loss = loss(net(poly_features[:n_train, :]), labels[:n_train])\n",
    "    training_loss.append(epoch_loss)\n",
    "    print(f\"epoch : {epoch}, training_loss : {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=4121011700000.0>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "loss(net(poly_features[n_train:, :]), labels[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}