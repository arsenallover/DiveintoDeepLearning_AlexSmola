{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600059309320",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_features, train_target), (test_features, test_target) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "train_target = tf.reshape(train_target, (-1, 1))\n",
    "test_target = tf.reshape(test_target, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.shuffle(buffer_size = 100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 64\n",
    "data_iter = load_data((train_features, train_target), batch_size)\n",
    "# next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(y_true, y_pred):\n",
    "    # To further stabilize the value when the logarithm is taken, set the\n",
    "    # value less than 1 as 1\n",
    "    clipped_preds = tf.clip_by_value(y_pred, 1, float('inf'))\n",
    "    return tf.sqrt(tf.reduce_mean(loss(\n",
    "        tf.math.log(y_true), tf.math.log(clipped_preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = tf.keras.models.Sequential()\n",
    "lin_reg.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "lin_reg.add(tf.keras.layers.Dense(5, activation = 'relu'))\n",
    "lin_reg.add(tf.keras.layers.Dense(3, activation = 'relu'))\n",
    "lin_reg.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.1)\n",
    "loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch : 0, training_loss : 62.75815963745117\nepoch : 1, training_loss : 24.664142608642578\nepoch : 2, training_loss : 28.78792953491211\nepoch : 3, training_loss : 17.72987937927246\nepoch : 4, training_loss : 11.17648696899414\nepoch : 5, training_loss : 12.671730041503906\nepoch : 6, training_loss : 9.46349811553955\nepoch : 7, training_loss : 9.49169635772705\nepoch : 8, training_loss : 8.649161338806152\nepoch : 9, training_loss : 8.545610427856445\n"
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "batch_size = 32\n",
    "data_iter = load_data((train_features, train_target), batch_size)\n",
    "for epoch in range(num_epoch):\n",
    "    for X, y in data_iter:\n",
    "        with tf.GradientTape() as tape:\n",
    "            yhat = lin_reg(X)\n",
    "            mse_loss = loss(yhat, y)\n",
    "            \n",
    "        # Gradient\n",
    "        params = lin_reg.trainable_variables\n",
    "        grads = tape.gradient(mse_loss, params)\n",
    "\n",
    "        # Update Gradient\n",
    "        optimizer.apply_gradients(zip(grads, params))\n",
    "    \n",
    "    training_loss = loss(train_target, lin_reg(train_features))\n",
    "    print(f\"epoch : {epoch}, training_loss : {training_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}