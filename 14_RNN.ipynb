{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('tf2.0': conda)",
   "display_name": "Python 3.7.9 64-bit ('tf2.0': conda)",
   "metadata": {
    "interpreter": {
     "hash": "22b3a9e511cc71c7e8c0c199ed3ba2f3f697f01009167188cfc9ddfa1a3c5b27"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    " ## RNN Equations\n",
    "\n",
    "1. Predict State\n",
    "\n",
    "$ H_t = \\phi(X_t W_{xh} + H_{t-1} W_{hh} + b_h) $\n",
    "\n",
    "2. Predict Output from State\n",
    "\n",
    "$ O_t = H_t W_{hy} + b_y $\n",
    "\n",
    "## Points\n",
    "* The state, H changes for every step\n",
    "\n",
    "* The weight matrix is always same across time steps during prediction -> drastic parameter reduction\n",
    "\n",
    "* 3 W, 2 b are the GD updateable parameters\n",
    "* Inputs is usually 3D -> num_examples, time_steps, dimension\n",
    "* dimension above is 1 -> univariate\n",
    "\n",
    "* At any step t, computations are:\n",
    "    1. concatenate $X_t, H_{t_1}$\n",
    "    2. feed this to FC layer with weights $ W_{xh}, W_{hh}$ -> perform activation\n",
    "    3. feed this to another FC output layer -> $O_t$\n",
    "     "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dimensions\n",
    "\n",
    "### State Prediction Step\n",
    "* $X_t$ = n * d (number of minibatch, input_size)\n",
    "\n",
    "* $W_{xh}$ = d * h (input_size, hidden_state_size)\n",
    "* $H_t$ = n * h (number of minibatch, hidden_state_size)\n",
    "\n",
    "* $W_{hh}$ = h * h (hidden_state_size, hidden_state_size)\n",
    "* $b_h$ = 1 * h (hidden_state_size) \n",
    "\n",
    "\n",
    "### Output Prediction Step\n",
    "* $W_{yh}$ = h * q (hidden_state_size, output_size)\n",
    "* $b_y$ = 1 * q  (output_size) \n",
    "\n",
    "## Forward Prop\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rnn_helper import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-2.1495504 ,  1.3647544 , -2.4028628 ,  0.20764503]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "n, d, h, q = 1, 3, 4, 1\n",
    "x, Wxh = tf.random.normal((n, d), 0, 1), tf.random.normal((d, h), 0, 1)\n",
    "h, Whh = tf.random.normal((n, h), 0, 1), tf.random.normal((h, h), 0, 1)\n",
    "tf.matmul(x, Wxh) + tf.matmul(h, Whh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-2.1495504 ,  1.3647543 , -2.4028628 ,  0.20764506]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Concat x, h and Wxh, Whh\n",
    "tf.matmul(tf.concat((x, h), 1), tf.concat((Wxh, Whh), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
    "\n",
    "train_random_iter, vocab_random_iter = load_data_time_machine(\n",
    "    batch_size, num_steps, use_random_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hidden):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return tf.random.normal(shape = shape, mean = 0, stddev = 0.01, dtype=tf.float32)\n",
    "\n",
    "    # Hidden Layers\n",
    "    Wxh = tf.Variable(normal((num_inputs, num_hidden)), dtype = tf.float32)\n",
    "    Whh = tf.Variable(normal((num_hidden, num_hidden)), dtype = tf.float32)\n",
    "    Wyh = tf.Variable(normal((num_hidden, num_outputs)), dtype = tf.float32)\n",
    "\n",
    "    bh = tf.Variable(tf.zeros(num_hidden), dtype = tf.float32)\n",
    "    by = tf.Variable(tf.zeros(num_outputs), dtype = tf.float32)\n",
    "    params = [Wxh, Whh, Wyh, bh, by]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hidden):\n",
    "    return (tf.zeros(shape = (batch_size, num_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    ''' inputs shape - (num_steps, batch_size, vocab_size)\n",
    "    '''\n",
    "    Wxh, Whh, Wyh, bh, by = params\n",
    "    H = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        # X.shape : (batch_size, vocab_size)\n",
    "        X = tf.reshape(X, [-1, Wxh.shape[0]])\n",
    "        H = tf.tanh(tf.matmul(X, Wxh) + tf.matmul(H, Whh) + bh)\n",
    "        Y = tf.matmul(H, Wyh) + by\n",
    "        outputs.append(Y)\n",
    "    return tf.concat(outputs, axis = 0), (H, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch:\n",
    "    def __init__(self, vocab_size, num_hidden, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hidden = vocab_size, num_hidden\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state, params):\n",
    "        X = tf.one_hot(tf.transpose(X), self.vocab_size)\n",
    "        X = tf.cast(X, tf.float32)\n",
    "        return self.forward_fn(X, state, params)\n",
    "\n",
    "    def begin_state(self, batch_size):\n",
    "        return self.init_state(batch_size, self.num_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(TensorShape([10, 28]), 1, TensorShape([2, 512]))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X = tf.reshape(tf.range(10), (2, 5))\n",
    "num_hiddens = 512\n",
    "model = RNNModelScratch(len(vocab), num_hiddens,\n",
    "                        init_rnn_state, rnn)\n",
    "state = model.begin_state(X.shape[0])\n",
    "params = get_params(len(vocab), num_hiddens)\n",
    "Y, new_state = model(X, state, params)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, model, vocab, params):  #@save\n",
    "    \"\"\"Generate new characters following the `prefix`.\"\"\"\n",
    "    state = model.begin_state(batch_size=1)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: tf.reshape(tf.constant([outputs[-1]]), (1, 1)).numpy()\n",
    "    for y in prefix[1:]:  # Warm-up period\n",
    "        _, state = model(get_input(), state, params)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # Predict `num_preds` steps\n",
    "        y, state = model(get_input(), state, params)\n",
    "        print(y.numpy())\n",
    "        outputs.append(int(y.numpy().argmax(axis=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[[[[[[[[[[[[[[-1.0938584e-03 -8.3082268e-04\n                 5.7275733e-03 -4.1611833e-03\n                 7.3284667e-05  1.2659185e-03\n                 5.7526413e-05  1.1367769e-03\n                 1.8775004e-03  3.4535432e-03\n                 1.6019269e-03  4.9708481e-04\n                 2.2623630e-03 -3.1120356e-03\n                 9.6344424e-04  2.0565109e-03\n                -2.6395558e-03 -3.0460595e-03\n                -3.9546560e-03  5.4238751e-03\n                 1.1826421e-03 -1.5820157e-03\n                -7.2282576e-04  4.4794474e-04\n                -1.4377866e-04  3.9684842e-03\n                -2.3874268e-03 -1.6274324e-03]]]]]]]]]]]]]]]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 28 into shape (1,)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7d24a24a228b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_ch8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time traveller '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-60decf44cfda>\u001b[0m in \u001b[0;36mpredict_ch8\u001b[1;34m(prefix, num_preds, model, vocab, params)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx_to_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 28 into shape (1,)"
     ]
    }
   ],
   "source": [
    "predict_ch8('time traveller ', 10, model, vocab, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}